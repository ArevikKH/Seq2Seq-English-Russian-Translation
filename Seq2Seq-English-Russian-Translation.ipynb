{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPkqR3MpXqWkw8zkcJRXXZX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Machine Translate"],"metadata":{"id":"Y0Fa1363EnhH"}},{"cell_type":"code","source":["!pip install tqdm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K9b67W2mKLKQ","executionInfo":{"status":"ok","timestamp":1742667359614,"user_tz":-240,"elapsed":3774,"user":{"displayName":"Arevik Khachatryan","userId":"06400131763786536191"}},"outputId":"1b34e8d6-7b20-45a2-d85e-066bd77141f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V_RHjw7VJ2ox","executionInfo":{"status":"ok","timestamp":1742667367070,"user_tz":-240,"elapsed":6038,"user":{"displayName":"Arevik Khachatryan","userId":"06400131763786536191"}},"outputId":"e9db5e33-2922-478c-e129-8652f03f8e3e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import pandas as pd\n","import string\n","import re\n","import random\n","from tqdm import tqdm\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","from sklearn.model_selection import train_test_split\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n"]},{"cell_type":"markdown","source":["Data Preprocessing"],"metadata":{"id":"-XkzRG65KUf_"}},{"cell_type":"code","source":["text_file_path = '/content/rus.txt'\n","with open(text_file_path) as t:\n","    text = t.read()\n","\n","def preprocess_text(text):\n","    text = re.sub(\"'\", '', text)\n","    text = ''.join(char for char in text if char not in string.punctuation)\n","    text = re.sub(\"[0-9]\", '', text)\n","    return text.lower()\n","\n","def return_sentences(text, num_lines=20000):\n","    text_lines = text.split('\\n')\n","    english_texts, russian_texts, english_words, russian_words = [], [], set(), set()\n","\n","    for text_line in tqdm(range(min(len(text_lines), num_lines))):\n","        if not text_lines[text_line].strip():\n","            continue\n","        preprocessed_text_line = preprocess_text(text_lines[text_line])\n","        tab_split_text = preprocessed_text_line.split('\\t')\n","        if len(tab_split_text) < 2:\n","            continue\n","\n","        english_texts.append(tab_split_text[0])\n","        russian_texts.append('<sos> ' + tab_split_text[1] + ' <eos>')\n","\n","        english_words.update(tab_split_text[0].split())\n","        russian_words.update(tab_split_text[1].split())\n","\n","    # Add special tokens\n","    english_words.add('<sos>')\n","    english_words.add('<eos>')\n","    russian_words.add('<sos>')\n","    russian_words.add('<eos>')\n","\n","    return english_texts, russian_texts, sorted(english_words), sorted(russian_words)\n","\n","english_texts, russian_texts, english_words, russian_words = return_sentences(text)\n","\n","# Create DataFrame\n","text_df = pd.DataFrame({'English': english_texts, 'Russian': russian_texts})\n","text_df['English Length'] = text_df['English'].apply(lambda x: len(x.split()))\n","text_df['Russian Length'] = text_df['Russian'].apply(lambda x: len(x.split()))\n","text_df = text_df.sample(frac=1, random_state=42)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pt2mzMYTKGYM","executionInfo":{"status":"ok","timestamp":1742667887184,"user_tz":-240,"elapsed":693,"user":{"displayName":"Arevik Khachatryan","userId":"06400131763786536191"}},"outputId":"b834d436-48e9-4aa2-d08e-feac42539535"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 20000/20000 [00:00<00:00, 63908.72it/s]\n"]}]},{"cell_type":"markdown","source":["Vocabulary & Lookup Tables"],"metadata":{"id":"ZmrDeNDwKXtb"}},{"cell_type":"code","source":["num_encoder_tokens = len(english_words)\n","num_decoder_tokens = len(russian_words) + 1\n","\n","english_lookup = {word: num for num, word in enumerate(english_words)}\n","russian_lookup = {word: num + 1 for num, word in enumerate(russian_words)}\n","russian_lookup['<sos>'] = 0  # Add <sos> with index 0\n","russian_lookup['<eos>'] = num_decoder_tokens - 1\n","russian_token_lookup = {num: word for word, num in russian_lookup.items()}\n"],"metadata":{"id":"FzgoWGHiKYjZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Dataset & Dataloader"],"metadata":{"id":"BEVMSz-2XZVM"}},{"cell_type":"code","source":["class TranslationDataset(Dataset):\n","    def __init__(self, english_texts, russian_texts, english_lookup, russian_lookup):\n","        self.english_texts = english_texts\n","        self.russian_texts = russian_texts\n","        self.english_lookup = english_lookup\n","        self.russian_lookup = russian_lookup\n","\n","    def __len__(self):\n","        return len(self.english_texts)\n","\n","    def __getitem__(self, idx):\n","        encoder_input = torch.tensor([self.english_lookup[word] for word in self.english_texts[idx].split()], dtype=torch.long)\n","        russian_words = self.russian_texts[idx].split()\n","        decoder_input = torch.tensor([self.russian_lookup[word] for word in russian_words[:-1]], dtype=torch.long)\n","        decoder_target = torch.tensor([self.russian_lookup[word] for word in russian_words[1:]], dtype=torch.long)\n","        return encoder_input, decoder_input, decoder_target\n","\n","def collate_fn(batch):\n","    encoder_inputs, decoder_inputs, decoder_targets = zip(*batch)\n","    return pad_sequence(encoder_inputs, batch_first=True), pad_sequence(decoder_inputs, batch_first=True), pad_sequence(decoder_targets, batch_first=True)\n","\n","\n","X_train, X_valid, y_train, y_valid = train_test_split(text_df['English'], text_df['Russian'], test_size=0.2, random_state=42)\n","\n","# Create dataloaders\n","batch_size = 32\n","train_dataset = TranslationDataset(X_train.tolist(), y_train.tolist(), english_lookup, russian_lookup)\n","valid_dataset = TranslationDataset(X_valid.tolist(), y_valid.tolist(), english_lookup, russian_lookup)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, num_workers=2)\n","valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, num_workers=2)\n"],"metadata":{"id":"8OIRPHuOXXDq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Model Definition"],"metadata":{"id":"jZLzvbjbXeGe"}},{"cell_type":"code","source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, embedding_dim, hidden_dim):\n","        super().__init__()\n","        self.embedding = nn.Embedding(input_dim, embedding_dim)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n","\n","    def forward(self, src):\n","        embedded = self.embedding(src)\n","        _, (hidden, cell) = self.lstm(embedded)\n","        return hidden, cell\n","\n","class Decoder(nn.Module):\n","    def __init__(self, output_dim, embedding_dim, hidden_dim):\n","        super().__init__()\n","        self.embedding = nn.Embedding(output_dim, embedding_dim)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n","        self.fc_out = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, input, hidden, cell):\n","        embedded = self.embedding(input.unsqueeze(1))\n","        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n","        return self.fc_out(output.squeeze(1)), hidden, cell\n","\n","class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n","        batch_size, trg_len = trg.shape\n","        trg_vocab_size = self.decoder.fc_out.out_features\n","        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(device)\n","\n","        hidden, cell = self.encoder(src)\n","        input = trg[:, 0]\n","\n","        for t in range(1, trg_len):\n","            output, hidden, cell = self.decoder(input, hidden, cell)\n","            outputs[:, t - 1] = output\n","            input = trg[:, t] if random.random() < teacher_forcing_ratio else output.argmax(1)\n","\n","        return outputs\n"],"metadata":{"id":"YKggRIN-Xbzs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Training Setup"],"metadata":{"id":"lLaopT9EXisc"}},{"cell_type":"code","source":["# Initialize model\n","embedding_dim, hidden_dim = 256, 512\n","encoder = Encoder(num_encoder_tokens, embedding_dim, hidden_dim).to(device)\n","decoder = Decoder(num_decoder_tokens, embedding_dim, hidden_dim).to(device)\n","model = Seq2Seq(encoder, decoder).to(device)\n","\n","# Optimizer and loss\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss(ignore_index=0)\n","\n","def train(model, dataloader, optimizer, criterion, clip=1.0):\n","    model.train()\n","    epoch_loss = 0\n","\n","    for src, trg_input, trg_output in tqdm(dataloader):\n","        src, trg_input, trg_output = src.to(device), trg_input.to(device), trg_output.to(device)\n","        optimizer.zero_grad()\n","        output = model(src, trg_input)\n","\n","        output_dim = output.shape[-1]\n","        loss = criterion(output.view(-1, output_dim), trg_output.view(-1))\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","    return epoch_loss / len(dataloader)\n","\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    train_loss = train(model, train_dataloader, optimizer, criterion)\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8dzKT4psXgYH","executionInfo":{"status":"ok","timestamp":1742667980853,"user_tz":-240,"elapsed":83670,"user":{"displayName":"Arevik Khachatryan","userId":"06400131763786536191"}},"outputId":"38f7d58d-7db4-4276-874c-c29b6972e9ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:09<00:00, 53.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Loss: 4.4228\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:08<00:00, 60.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/10, Loss: 2.9168\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:08<00:00, 59.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/10, Loss: 1.9810\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:08<00:00, 58.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/10, Loss: 1.4148\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:08<00:00, 60.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/10, Loss: 1.1193\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:08<00:00, 60.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/10, Loss: 1.0000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:07<00:00, 63.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/10, Loss: 0.9284\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:08<00:00, 60.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8/10, Loss: 0.8954\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:08<00:00, 59.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9/10, Loss: 0.8664\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:07<00:00, 62.60it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Loss: 0.8579\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["def translate_sentence(sentence, model, english_lookup, russian_token_lookup, max_length=50):\n","    sentence = preprocess_text(sentence)\n","    input_tokens = sentence.split()\n","\n","    # Convert English words to token IDs and add batch dimension: shape (1, sequence_length)\n","    input_tensor = torch.tensor([english_lookup.get(word, 0) for word in input_tokens], dtype=torch.long).to(device)\n","    input_tensor = input_tensor.unsqueeze(0)\n","\n","    # Initialize the decoder input with <sos> (no extra unsqueeze, so shape is (1,))\n","    decoder_input = torch.tensor([russian_lookup['<sos>']], dtype=torch.long).to(device)\n","\n","    model.eval()\n","    with torch.no_grad():\n","        hidden, cell = model.encoder(input_tensor)\n","        output_tokens = []\n","\n","        for t in range(max_length):\n","            output, hidden, cell = model.decoder(decoder_input, hidden, cell)\n","\n","            top1 = output.argmax(1).item()\n","            output_tokens.append(top1)\n","\n","            if top1 == russian_lookup['<eos>']:\n","                break\n","\n","            # Update decoder input\n","            decoder_input = torch.tensor([top1], dtype=torch.long).to(device)\n","\n","    # Convert token IDs to Russian words\n","    translated_words = [russian_token_lookup[token] for token in output_tokens]\n","    return ' '.join(translated_words)\n"],"metadata":{"id":"OBsrGRqUK1oe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# english_sentence = \"hello how are you\"\n","# Input (English): hello how are you\n","# Translated (Russian): привет как дела —\n","english_sentence = \"I am working\"\n","\n","translated_sentence = translate_sentence(english_sentence, model, english_lookup, russian_token_lookup)\n","\n","print(f\"Input (English): {english_sentence}\")\n","print(f\"Translated (Russian): {translated_sentence}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TmKn6XI4HS-x","executionInfo":{"status":"ok","timestamp":1742669185473,"user_tz":-240,"elapsed":62,"user":{"displayName":"Arevik Khachatryan","userId":"06400131763786536191"}},"outputId":"45b07e2f-8f53-4cf7-f14e-e3764521174a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input (English): I am working\n","Translated (Russian): я работаю —\n"]}]}]}
